{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54c03ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.6867, acc.: 70.31%] [G loss: 0.6931]\n",
      "1000 [D loss: 0.7403, acc.: 43.16%] [G loss: 0.6006]\n",
      "2000 [D loss: 0.7453, acc.: 43.09%] [G loss: 0.5928]\n",
      "3000 [D loss: 0.7471, acc.: 43.11%] [G loss: 0.5900]\n",
      "4000 [D loss: 0.7480, acc.: 43.12%] [G loss: 0.5885]\n",
      "5000 [D loss: 0.7485, acc.: 43.12%] [G loss: 0.5876]\n",
      "6000 [D loss: 0.7490, acc.: 43.14%] [G loss: 0.5870]\n",
      "7000 [D loss: 0.7492, acc.: 43.13%] [G loss: 0.5865]\n",
      "8000 [D loss: 0.7494, acc.: 43.10%] [G loss: 0.5862]\n",
      "9000 [D loss: 0.7496, acc.: 43.09%] [G loss: 0.5859]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load and preprocess MNIST\n",
    "(x_train, y_train), (_, _) = mnist.load_data()\n",
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "num_classes = 10\n",
    "img_shape = x_train.shape[1:]\n",
    "\n",
    "# Generator\n",
    "def build_generator(latent_dim, num_classes):\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    label_embedding = layers.Embedding(num_classes, latent_dim)(label)\n",
    "    label_embedding = layers.Flatten()(label_embedding)\n",
    "    model_input = layers.multiply([noise, label_embedding])\n",
    "    x = layers.Dense(128)(model_input)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dense(np.prod(img_shape), activation='tanh')(x)\n",
    "    img = layers.Reshape(img_shape)(x)\n",
    "    return Model([noise, label], img, name=\"generator\")\n",
    "\n",
    "# Discriminator\n",
    "def build_discriminator(img_shape, num_classes):\n",
    "    img = Input(shape=img_shape)\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    label_embedding = layers.Embedding(num_classes, np.prod(img_shape))(label)\n",
    "    label_embedding = layers.Flatten()(label_embedding)\n",
    "    flat_img = layers.Flatten()(img)\n",
    "    model_input = layers.multiply([flat_img, label_embedding])\n",
    "    x = layers.Dense(512)(model_input)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    return Model([img, label], x, name=\"discriminator\")\n",
    "\n",
    "latent_dim = 100\n",
    "generator = build_generator(latent_dim, num_classes)\n",
    "discriminator = build_discriminator(img_shape, num_classes)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Save model architectures\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "plot_model(generator, to_file=\"visualizations/generator_architecture.png\", show_shapes=True, show_layer_names=True)\n",
    "plot_model(discriminator, to_file=\"visualizations/discriminator_architecture.png\", show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Combined model\n",
    "noise = Input(shape=(latent_dim,))\n",
    "label = Input(shape=(1,), dtype='int32')\n",
    "img = generator([noise, label])\n",
    "discriminator.trainable = False\n",
    "valid = discriminator([img, label])\n",
    "combined = Model([noise, label], valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Visualization function for generated images\n",
    "def save_generated_images(epoch, generator, latent_dim, num_classes):\n",
    "    r, c = 2, 5  # 2 rows, 5 columns for 10 digits\n",
    "    noise = np.random.normal(0, 1, (num_classes, latent_dim))\n",
    "    labels = np.arange(0, num_classes).reshape(-1, 1)\n",
    "    gen_imgs = generator.predict([noise, labels], verbose=0)\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale to [0, 1]\n",
    "\n",
    "    fig, axs = plt.subplots(r, c, figsize=(c*2, r*2))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].set_title(f\"Digit: {cnt}\")\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.suptitle(f\"Generated digits at epoch {epoch}\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"visualizations/generated_{epoch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Training loop\n",
    "epochs = 10000\n",
    "batch_size = 64\n",
    "half_batch = batch_size // 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train Discriminator\n",
    "    idx = np.random.randint(0, x_train.shape[0], half_batch)\n",
    "    imgs, labels = x_train[idx], y_train[idx]\n",
    "    noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "    gen_labels = np.random.randint(0, num_classes, half_batch).reshape(-1, 1)\n",
    "    gen_imgs = generator.predict([noise, gen_labels], verbose=0)\n",
    "    d_loss_real = discriminator.train_on_batch([imgs, labels], np.ones((half_batch, 1)))\n",
    "    d_loss_fake = discriminator.train_on_batch([gen_imgs, gen_labels], np.zeros((half_batch, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Train Generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    sampled_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
    "    valid_y = np.ones((batch_size, 1))\n",
    "    g_loss = combined.train_on_batch([noise, sampled_labels], valid_y)\n",
    "\n",
    "    # Print and visualize progress\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"{epoch} [D loss: {d_loss[0]:.4f}, acc.: {100*d_loss[1]:.2f}%] [G loss: {g_loss:.4f}]\")\n",
    "        save_generated_images(epoch, generator, latent_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e2c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
